{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, date\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from easydict import EasyDict\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read in data\n",
    "filename = \"C:/Users/phili/Downloads/Seattle_Real_Time_Fire_911_Calls.csv\"\n",
    "raw_df = pd.read_csv(filename)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def preprocessing(raw_df):\n",
    "    \"\"\"\n",
    "    Prepocesses the data and returns dataframe\n",
    "    :param raw_df: pd.Dataframe\n",
    "    :return: df(pd.Dataframe)\n",
    "    \"\"\"\n",
    "    # Divide date into Years,Months,Days,Hours\n",
    "    raw_df[\"Datetime\"]= raw_df[\"Datetime\"].apply(lambda x: datetime.strptime(x, '%m/%d/%Y %I:%M:%S %p'))\n",
    "    raw_df[\"Year\"] = raw_df[\"Datetime\"].apply(lambda x: int(x.year))\n",
    "    raw_df = raw_df[raw_df[\"Year\"] >= 2014]\n",
    "    raw_df[\"Month\"] = raw_df[\"Datetime\"].apply(lambda x: int(x.month))\n",
    "    raw_df[\"Day\"] = raw_df[\"Datetime\"].apply(lambda x: int(x.day))\n",
    "    raw_df[\"Hour\"] =raw_df[\"Datetime\"].apply(lambda x: int(x.hour))\n",
    "\n",
    "    raw_df.dropna(inplace=True) # drop null values\n",
    "\n",
    "    df = raw_df.copy()\n",
    "    # drop features we won't use\n",
    "    df.drop([\"Address\", \"Type\", \"Report Location\", \"Incident Number\"], axis=1, inplace=True)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature Engineering"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_target_variable(df):\n",
    "    \"\"\"\n",
    "    Creates the target variable: Hourly Call Volume (Number of Calls per hour)\n",
    "    :param df: pd.Dataframe, containing the preprocessed data\n",
    "    :return: df (with target variable)\n",
    "    \"\"\"\n",
    "    y_m_d= df.apply(lambda x: (int(x[\"Year\"]), int(x[\"Month\"]),int(x[\"Day\"]), int(x[\"Hour\"])), axis=1)\n",
    "    hourly_call_volume = df.groupby(by=[\"Year\", \"Month\", \"Day\", \"Hour\"]).count()[\"Latitude\"].to_dict()\n",
    "    df[\"Hourly Call Volume\"] = y_m_d.map(hourly_call_volume)\n",
    "    return df\n",
    "\n",
    "def add_daily_call_volume_feat(df):\n",
    "    \"\"\"\n",
    "    Adds a new feature: Daily Call Volume (Number of calls per day)\n",
    "    :param df: pd.Dataframe, containing the preprocessed data\n",
    "    :return: df (with new feature)\n",
    "    \"\"\"\n",
    "    m_d = df.apply(lambda x: (int(x[\"Year\"]), int(x[\"Month\"]),int(x[\"Day\"])), axis=1)\n",
    "    avg_daily_call_volumes = df.groupby(by=[\"Year\", \"Month\", \"Day\"])[\"Hour\"].count().to_dict() #.apply(lambda x: x/df[\"Year\"].unique().size)\n",
    "    df[\"Daily Call Volume\"] = m_d.map(avg_daily_call_volumes)\n",
    "    return df\n",
    "\n",
    "def get_season(in_datetime):\n",
    "    \"\"\"\n",
    "    Returns season of datetime object\n",
    "    :param in_datetime: datetime.datetime\n",
    "    :return: season (str): winter, spring, summer or fall\n",
    "    \"\"\"\n",
    "    Y = 2000 # dummy leap year to allow input X-02-29 (leap day)\n",
    "    seasons = [('winter', (date(Y,  1,  1),  date(Y,  3, 20))),\n",
    "               ('spring', (date(Y,  3, 21),  date(Y,  6, 20))),\n",
    "               ('summer', (date(Y,  6, 21),  date(Y,  9, 22))),\n",
    "               ('fall', (date(Y,  9, 23),  date(Y, 12, 20))),\n",
    "               ('winter', (date(Y, 12, 21),  date(Y, 12, 31)))]\n",
    "\n",
    "    assert isinstance(in_datetime, datetime), \"Not a datetime object!\"\n",
    "    in_datetime = in_datetime.replace(year=Y)\n",
    "    return next(season for season, (start, end) in seasons\n",
    "                if start <= in_datetime <= end)\n",
    "\n",
    "def create_features(df):\n",
    "    \"\"\"\n",
    "    Creates several new features and returns an Easydict containing the train and test data\n",
    "    :param df: pd.Dataframe, containing preprocessed data\n",
    "    :return: EasyDict containing both train and test data\n",
    "    \"\"\"\n",
    "    df[\"Season\"]= df[\"Datetime\"].apply(lambda x: get_season(x))\n",
    "    df[\"Weekday\"]= df[\"Datetime\"].apply(lambda x: datetime.weekday(x))\n",
    "    df = add_daily_call_volume_feat(df)\n",
    "\n",
    "    df = create_target_variable(df)\n",
    "\n",
    "    df.sort_values(by='Datetime', inplace=True) # Sort by Date\n",
    "    df.drop([\"Datetime\"], axis=1, inplace=True) # All necessary information already exported to other columns\n",
    "\n",
    "    # We want to predict the hourly call volume of 2019\n",
    "    df_train = df[df[\"Year\"] < 2019]\n",
    "    df_test = df[df[\"Year\"] == 2019]\n",
    "\n",
    "    target_train = df_train.pop(\"Hourly Call Volume\")\n",
    "    target_test = df_test.pop(\"Hourly Call Volume\")\n",
    "\n",
    "    return EasyDict(X_train=df_train,y_train=target_train, X_test=df_test, y_test=target_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def training(x_train, y_train):\n",
    "    \"\"\"\n",
    "    Trains the Decision Tree\n",
    "    :param x_train: pd.Dataframe, containing the features of the training data\n",
    "    :param y_train: pd.Series, containing the target variable of the training data\n",
    "    \"\"\"\n",
    "\n",
    "    numerical_cols = x_train.select_dtypes('number').columns\n",
    "    categorical_cols = pd.Index(np.setdiff1d(x_train.columns, numerical_cols))\n",
    "    rng = np.random.RandomState(1)\n",
    "    tree = AdaBoostRegressor(\n",
    "        DecisionTreeRegressor(max_depth=5), n_estimators=300, random_state=rng)\n",
    "\n",
    "    numerical_pipe = Pipeline([\n",
    "        ('scaler', StandardScaler())])\n",
    "\n",
    "    categorical_pipe = Pipeline([(\n",
    "        'encoder', OneHotEncoder(drop='first', handle_unknown='error'))])\n",
    "\n",
    "    preprocessors = ColumnTransformer(transformers=[\n",
    "        ('num', numerical_pipe, numerical_cols),\n",
    "        ('cat', categorical_pipe, categorical_cols)\n",
    "    ])\n",
    "\n",
    "    pipe = Pipeline([('preprocessors', preprocessors), ('tree', tree)])\n",
    "\n",
    "    i=100000\n",
    "    pipe.fit(x_train.iloc[:i,:], y_train.iloc[:i])\n",
    "\n",
    "    joblib.dump(pipe, \"./dec_tree_pipe.joblib\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test_tree(x_train, y_train, x_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluates the\n",
    "    :param x_train: pd.Dataframe, containing the features of the training data\n",
    "    :param y_train: pd.Series, containing the target variable of the training data\n",
    "    :param x_test: pd.Dataframe, containing the features of the test data\n",
    "    :param y_test: pd.Series, containing the target variable of the test data\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    pipe = joblib.load(\"./dec_tree_pipe.joblib\")\n",
    "\n",
    "    train_pred = pipe.predict(x_train)\n",
    "    train_loss = mean_squared_error(y_train, train_pred)\n",
    "    train_R2_score = pipe.score(x_train, y_train)\n",
    "    print('Training MSE Loss: {} \\n Test R2 score {}'.format(train_loss, train_R2_score))\n",
    "\n",
    "    test_pred = pipe.predict(x_test)\n",
    "    test_loss = mean_squared_error(y_test, test_pred)\n",
    "    test_R2_score  = pipe.score(x_test, y_test)\n",
    "    print('Test MSE Loss: {} \\n Test R2 score {}'.format(test_loss, test_R2_score))\n",
    "    print(type(test_pred))\n",
    "    return test_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = preprocessing(raw_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = create_features(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "i=100000\n",
    "# Choose only a subset of training data in case of limited computational resources\n",
    "data.X_train, data.y_train = shuffle(data.X_train, data.y_train, random_state=0)\n",
    "data.X_train, data.y_train = data.X_train.iloc[:i,:], data.y_train.iloc[:i]\n",
    "\n",
    "training(data.X_train, data.y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions = test_tree(data.X_train, data.y_train, data.X_test, data.y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.concat([data.X_test, data.y_test], axis=1) # useful to get Hourly Call Volume according to hours and days\n",
    "df.reset_index(inplace=True)\n",
    "y_test_2 = data.y_test.reset_index(drop=True)\n",
    "indices = []\n",
    "# Get Hourly Call Volume for\n",
    "for day in range(1,8):\n",
    "    for hour in range(0,24):\n",
    "        indices.append(df[(df[\"Month\"]==3) & (df[\"Day\"]==day) & (df[\"Hour\"]==hour)][\"Hourly Call Volume\"].index[0])\n",
    "\n",
    "plt.plot(np.arange(7*24), y_test_2[indices])\n",
    "plt.plot(np.arange(7*24), predictions[indices])\n",
    "plt.xlabel(\"Hour\")\n",
    "plt.ylabel(\"Call Volume\")\n",
    "plt.title(\"Hourly Call Volume 1st week of March'19\")\n",
    "plt.legend([\"True\", \"Prediction\"])\n",
    "plt.savefig(\"Hourly Call Volume 1st week March'19.png\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}